# -*- coding: utf-8 -*-
"""Programming _For_DataAnalysis_Assessment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18RGuXyyrrMRf7B8bR_KRez9eRP3ghBqJ

### **Mounting the google drive to the colab environment:**
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/Assessment_Final_Data'

"""# TASK 1: DATA HANDLING

## LOADING THE DATASET
"""

# Commented out IPython magic to ensure Python compatibility.
# %ls

import pandas as pd
import glob

# Get all CSV files in the folder
csv_files = glob.glob("/content/drive/MyDrive/Assessment_Final_Data/*.csv")
csv_files

"""## COMBINING ALL THE DATASETS TO ONE DATAFRAME"""

# Read and combine all CSV files
combined_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)
combined_df

df1 = combined_df.drop_duplicates()
df1

# Save to a new CSV file
df1.to_csv("combined_output.csv", index=False)

print("All CSV files have been merged into 'combined_output.csv'.")

"""# TASK2 : EDA(EXPLORATORY DATA ANALYSIS)

## A) FUNDAMENTAL DATA UNDERSTANDING
"""

df1.shape

df1.columns

df1.info()

selected_columns = ['No', 'year', 'month', 'day', 'hour', 'PM2.5', 'PM10', 'SO2', 'NO2','CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station']
df = df1[selected_columns]
df

# Missing values
def missing_values_table(df):
        # Total missing values
        mis_val = df.isnull().sum()

        # Percentage of missing values
        mis_val_percent = 100 * df.isnull().sum() / len(df)

        # Make a table with the results
        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
        print(mis_val_table)

        # Rename the columns
        mis_val_table_ren_columns = mis_val_table.rename(
        columns = {0 : 'Missing Values', 1 : '% of Total Values'})

        # Sort the table by percentage of missing descending
        mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(
        '% of Total Values', ascending=False)

        # Return the dataframe with missing information
        return mis_val_table_ren_columns

missing_values= missing_values_table(df)
missing_values.style.background_gradient(cmap='RdYlGn_r')

df.describe()

df.isnull().sum()

"""# Finding Out Outliers Using IQR(INTER QUARTILE RANGE) Method one of the common method used to find outliers in skewed data."""

# Choose your column (e.g., 'PM2.5')
column = 'CO'

Q1 = df['CO'].quantile(0.25)
Q3 = df['CO'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['CO'] < lower_bound) | (df['CO'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'CO'}:", outliers.shape[0])
print(outliers[['CO']])

# Choose your column (e.g., 'PM2.5')
column = 'O3'

Q1 = df['O3'].quantile(0.25)
Q3 = df['O3'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['O3'] < lower_bound) | (df['O3'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'O3'}:", outliers.shape[0])
print(outliers[['O3']])

# Choose your column (e.g., 'PM2.5')
column = 'NO2'

Q1 = df['NO2'].quantile(0.25)
Q3 = df['NO2'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['NO2'] < lower_bound) | (df['NO2'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'NO2'}:", outliers.shape[0])
print(outliers[['NO2']])

# Choose your column (e.g., 'PM2.5')
column = 'SO2'

Q1 = df['SO2'].quantile(0.25)
Q3 = df['SO2'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['SO2'] < lower_bound) | (df['SO2'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'SO2'}:", outliers.shape[0])
print(outliers[['SO2']])

# Choose your column (e.g., 'PM2.5')
column = 'PM2.5'

Q1 = df['PM2.5'].quantile(0.25)
Q3 = df['PM2.5'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['PM2.5'] < lower_bound) | (df['PM2.5'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'PM2.5'}:", outliers.shape[0])
print(outliers[['PM2.5']])

# Choose your column (e.g., 'PM2.5')
column = 'PM10'

Q1 = df['PM10'].quantile(0.25)
Q3 = df['PM10'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['PM10'] < lower_bound) | (df['PM10'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'PM10'}:", outliers.shape[0])
print(outliers[['PM10']])

# Choose your column (e.g., 'PM2.5')
column = 'TEMP'

Q1 = df['TEMP'].quantile(0.25)
Q3 = df['TEMP'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['TEMP'] < lower_bound) | (df['TEMP'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'TEMP'}:", outliers.shape[0])

# Choose your column (e.g., 'PM2.5')
column = 'PRES'

Q1 = df['PRES'].quantile(0.25)
Q3 = df['PRES'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['PRES'] < lower_bound) | (df['PRES'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'PRES'}:", outliers.shape[0])

# Choose your column (e.g., 'PM2.5')
column = 'DEWP'

Q1 = df['DEWP'].quantile(0.25)
Q3 = df['DEWP'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['DEWP'] < lower_bound) | (df['DEWP'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'DEWP'}:", outliers.shape[0])

# Choose your column (e.g., 'PM2.5')
column = 'RAIN'

Q1 = df['RAIN'].quantile(0.25)
Q3 = df['RAIN'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['RAIN'] < lower_bound) | (df['RAIN'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'RAIN'}:", outliers.shape[0])
print(outliers[['RAIN']])

# Choose your column (e.g., 'PM2.5')
column = 'WSPM'

Q1 = df['WSPM'].quantile(0.25)
Q3 = df['WSPM'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out the outliers
outliers = df[(df['WSPM'] < lower_bound) | (df['WSPM'] > upper_bound)]

# Display outliers
print(f"Number of outliers in {'WSPM'}:", outliers.shape[0])
print(outliers[['WSPM']])

import pandas as pd

# Fill missing values in 'CO' with the median because it has outliers in that data
df['CO'].fillna(df['CO'].median(), inplace=True)

# Fill missing values in 'O3' with the median because it has outliers in that data
df['O3'].fillna(df['O3'].median(), inplace=True)

# Fill missing values in 'NO2' with the median because it has outliers in that data
df['NO2'].fillna(df['NO2'].median(), inplace=True)

# Fill missing values in 'SO2' with the median because it has outliers in that data
df['SO2'].fillna(df['SO2'].median(), inplace=True)

# Fill missing values in 'PM2.5' with the median because it has outliers in that data
df['PM2.5'].fillna(df['PM2.5'].median(), inplace=True)

# Fill missing values in 'PM10' with the median because it has outliers in that data
df['PM10'].fillna(df['PM10'].median(), inplace=True)

# Fill missing values in 'RAIN' with the median because it has outliers in that data
df['RAIN'].fillna(df['RAIN'].median(), inplace=True)

# Fill missing values in 'WSPM' with the median because it has outliers in that data
df['WSPM'].fillna(df['WSPM'].median(), inplace=True)

# Fill missing values in 'TEMP' with the mean beacuse it doesn't have any outliers
df['TEMP'].fillna(df['TEMP'].mean(), inplace=True)

# Fill missing values in 'PRES' with the mean beacuse it doesn.t have any outliers
df['PRES'].fillna(df['PRES'].mean(), inplace=True)

# Fill missing values in 'DEWP' with the mean because it doesn't have any outliers
df['DEWP'].fillna(df['DEWP'].mean(), inplace=True)

# Fill missing values in 'wd' with the mode (most common value) because it is a categorical column
df['wd'].fillna(df['wd'].mode()[0], inplace=True)


# Verify that all missing values have been filled
print(df.isnull().sum())

print(df.isnull().sum())

df['solid_pollutants'] = df[['PM2.5', 'PM10']].sum(axis=1, skipna=True)
df['solid_pollutants']

df['gas_pollutants'] = df[['SO2', 'NO2', 'CO', 'O3']].sum(axis=1, skipna=True)
df['gas_pollutants']

print(df.columns)

print(df.columns)

# Combine date parts into a datetime column
df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])
df['datetime']

# Extract features from datetime
df['dayofweek'] = df['datetime'].dt.dayofweek       # Monday = 0
df['dayofweek']

df['is_weekend'] = df['dayofweek'].apply(lambda x: 1 if x >= 5 else 0)
df['is_weekend']

df['temp_dewp_diff'] = df['TEMP'] - df['DEWP']
df = df.sort_values(by='temp_dewp_diff', ascending=False).reset_index(drop=True) #Larger Difference results In Lower Humidity
df

df.info()

df.describe().T

"""## Insights Which we got from the summary statistics:

1.This dataset shows that timeline is from 03/01/2013 to 02/28/2017 based on the minimum and maximum dates as well as mean implies that it is 03/01/2015

2.Solid Pollutants which include PM2.5 and PM10

a)PM2.5 which has Mean of 78.7 µg/m³ whereas PM10 which has a Mean of 102 µg/m³ both of them has an maximum of 999 which is closer to 1000 that means it is extremely high pollution causing pollutants.

3.Gas Pollutants which include SO2,NO2,CO,O3 each of them also have an huge impact on airpollution

a)CO(Carbon Monoxide):which has highest mean of over 1202 µg/m³ and with the highest range of 10000.0 µg/m³ shows that severe air pollution causing by this gas.

b)O3(Ozone): which has a mean of 56.5 µg/m³ and with the highest value ranging at 674 µg/m³.

c)NO2(Nitrogen Dioxide):which has a mean of 48.9 µg/m³ with the highest value as 264 µg/m³ which might result in acid rains as well.

d)SO2(Sulfur Dioxide) which has a mean of 14.85 µg/m³ with the highest value as 411 µg/m³ might impact on climate changes.




"""

df.columns

import plotly.express as px

# First, ensure your columns exist
assert 'solid_pollutants' in df.columns
assert 'gas_pollutants' in df.columns
assert 'TEMP' in df.columns

# Melt the DataFrame to long format for comparison plotting
df_melted = df[['datetime', 'solid_pollutants', 'gas_pollutants', 'TEMP']].melt(
    id_vars=['datetime', 'TEMP'],
    value_vars=['solid_pollutants', 'gas_pollutants'],
    var_name='Pollutant_Type',
    value_name='Pollution_Level'
)

# Create an interactive scatter plot with trendlines
fig = px.scatter(
    df_melted,
    x='Pollution_Level',
    y='TEMP',
    color='Pollutant_Type',
    trendline='ols',
    title='Comparison of Solid and Gas Pollutants vs Temperature',
    labels={'Pollution_Level': 'Pollutant Concentration', 'TEMP': 'Temperature (°C)'}
)

fig.show()

pollutants = ['PM2.5', 'PM10', 'SO2', 'NO2','CO', 'O3']
pol=df[pollutants].mean()
pollutants_df=pol.to_frame().reset_index()
pollutants_df.columns=['Pollutant','Level']
pollutants_df

import matplotlib.pyplot as plt

# Step 1: Calculate average of each pollutant
pollutants = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']
avg_pollution = df[pollutants].mean()

# Step 2: Colors — red for dominant, green for least
colors = ['red', 'orange', 'yellow', 'lightblue', 'lightgreen', 'green']

# Step 3: Explode each slice slightly for clarity
explode = [0.1] * len(avg_pollution)  # This must be same length as pollutants (6)

# Step 4: Create Pie Chart
plt.figure(figsize=(8, 8))
plt.pie(
    avg_pollution,
    labels=avg_pollution.index,
    autopct='%1.1f%%',
    startangle=140,
    colors=colors,
    explode=explode,
    shadow=True
)
plt.title("Dominant Pollutants in China (Average Levels)")
plt.axis('equal')  # Makes the pie chart a circle
plt.show()

import pandas as pd

pollutants = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']

# Group data by 'State' and calculate the mean of each pollutant
areawise_pollution_means = df.groupby('station')[pollutants].mean()

# Find the dominant pollutant in each state
dominant_pollutant_by_area = areawise_pollution_means.idxmax(axis=1)

# Convert the result to a DataFrame for better readability
dominant_pollutant_df = dominant_pollutant_by_area.reset_index()
dominant_pollutant_df.columns = ['station', 'Dominant Pollutant']

# Display the results
dominant_pollutant_df

import matplotlib.pyplot as plt
import seaborn as sns

# Filter the DataFrame to include only numeric columns
# This assumes you want to include only the pollutants columns
pollutants = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']
numeric_pollutants_df = df[pollutants]

# Convert data to numeric (this will handle any non-numeric values)
numeric_pollutants_df = numeric_pollutants_df.apply(pd.to_numeric, errors='coerce')

# Drop rows with any NaN values (if any)
numeric_pollutants_df = numeric_pollutants_df

# Calculate the correlation matrix
correlation_matrix = numeric_pollutants_df.corr()

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1, center=0)
plt.title('Correlation Heatmap of Pollutants')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

import plotly.express as px
import pandas as pd

# Step 1: Ensure month is integer and present
df['month'] = df['month'].astype(int)

# Step 2: Define pollutant columns
pollutant_cols = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']

# Step 3: Group by month and calculate mean
monthly_avg = df.groupby('month')[pollutant_cols].mean().reset_index()

# Step 4: Melt the DataFrame for plotting
monthly_melted = monthly_avg.melt(id_vars='month', var_name='Pollutant', value_name='Average_Level')

# Step 5: Create a grouped bar chart
fig = px.bar(
    monthly_melted,
    x='month',
    y='Average_Level',
    color='Pollutant',
    barmode='group',
    title='Month-wise Comparison of Air Pollutants',
    labels={'month': 'Month', 'Average_Level': 'Average Pollutant Level (µg/m³)'}
)

fig.show()

import plotly.express as px
import pandas as pd

# Step 1: Ensure 'year' column is int
df['year'] = df['year'].astype(int)

# Step 2: Define pollutant columns
pollutant_cols = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']

# Step 3: Group by year and calculate mean for each pollutant
yearly_avg = df.groupby('year')[pollutant_cols].mean().reset_index()

# Step 4: Add total pollution per year
yearly_avg['Total_Pollution'] = yearly_avg[pollutant_cols].sum(axis=1)

# Step 5: Find the dominant pollutant for each year
yearly_avg['Dominant_Pollutant'] = yearly_avg[pollutant_cols].idxmax(axis=1)

# Step 6: Sort by Total_Pollution to assign colors
yearly_avg = yearly_avg.sort_values(by='Total_Pollution', ascending=True).reset_index(drop=True)

# Step 7: Assign colors from green to red based on pollution ranking
color_scale = ['green', 'lightgreen', 'yellow', 'orange', 'darkred', 'red']
num_years = len(yearly_avg)
yearly_avg['Color'] = pd.cut(
    yearly_avg['Total_Pollution'],
    bins=num_years,
    labels=color_scale[:num_years]
).astype(str)

# Step 8: Plot the chart with dominant gas as hover label
fig = px.bar(
    yearly_avg,
    x='year',
    y='Total_Pollution',
    color='Color',
    color_discrete_map={c: c for c in color_scale},
    title='Year-wise Total Pollution with Dominant Pollutant',
    labels={'Total_Pollution': 'Total Pollution (µg/m³)', 'year': 'Year'},
    hover_data=['Dominant_Pollutant']
)

# Optional: Show dominant pollutant as text label on bars
fig.update_traces(text=yearly_avg['Dominant_Pollutant'], textposition='outside', marker_line_color='black', marker_line_width=1)

fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
fig.show()

df['year'] = df['year'].astype(int)
df['month'] = df['month'].astype(int)
df['day'] = df['day'].astype(int)

# Step 2: Combine year, month, and day into a single date column
df['date'] = pd.to_datetime(df[['year', 'month', 'day']])

print(df[['year', 'month', 'day', 'date']].head())

import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd

# Assuming df1 and pollutants are already defined
# Group by Year and Month to calculate the monthly average for each pollutant
monthly_avg = df.groupby(['year', 'month'])[pollutants].mean().reset_index()

# Create a Date column from Year and Month
monthly_avg['Date'] = pd.to_datetime(monthly_avg[['year', 'month']].assign(DAY=1))

# Create subplots for each pollutant
fig = make_subplots(rows=len(pollutants), cols=1, subplot_titles=[f'{pollutant} Monthly Average Concentration Over Time' for pollutant in pollutants])

# Add traces for each pollutant
for i, pollutant in enumerate(pollutants):
    fig.add_trace(
        go.Scatter(
            x=monthly_avg['Date'],
            y=monthly_avg[pollutant],
            mode='lines+markers',
            name=pollutant,
            line=dict(color='blue', width=2),
            marker=dict(size=8),
            opacity=0.7
        ),
        row=i+1, col=1
    )

# Update layout
fig.update_layout(
    title_text='Monthly Average Concentrations of Pollutants Over Time',
    title_font_size=24,
    showlegend=False,
    height=300 * len(pollutants),  # Adjust height based on the number of pollutants
    width=1000
)

# Update y-axis labels
for i, pollutant in enumerate(pollutants):
    fig.update_yaxes(title_text=f'{pollutant} (ug/m3)', row=i+1, col=1)

# Update x-axis labels
fig.update_xaxes(title_text='Date', row=len(pollutants), col=1)

# Rotate x-axis labels
fig.update_xaxes(tickangle=45)

# Show the plot
fig.show()

import plotly.express as px

# Step 1: Scatter plots for each feature against temperature
# This will show the relationship between temperature and other factors like rain, windspeed, dewpoint, pressure

# Create a DataFrame with relevant columns for easy plotting
df_temp_effect = df[['TEMP', 'RAIN', 'WSPM', 'DEWP', 'PRES']]

# Step 2: Create subplots for better visualization of all relationships
fig = px.scatter_matrix(
    df_temp_effect,
    dimensions=['TEMP', 'RAIN', 'WSPM', 'DEWP', 'PRES'],
    title="Effect of Temperature on Rain, Windspeed, Dewpoint, and Pressure",
    labels={'TEMP': 'Temperature (°C)', 'RAIN': 'Rain (mm)', 'WSPM': 'Windspeed (km/h)', 'DEWP': 'Dewpoint (°C)', 'PRES': 'Pressure (hPa)'}
)

# Step 3: Show the graph
fig.show()

import pandas as pd
import matplotlib.pyplot as plt

# Assuming df is your DataFrame with pollutant data
pollutant_columns = ['PM2.5','PM10','SO2','NO2','CO','O3']

# Step 1: Group by station and calculate mean pollutant concentrations
mean_pollutant_by_station = df.groupby('station')[pollutant_columns].mean()

# Step 2: Find the top 10 stations for each pollutant
top_stations = {}
for pollutant in pollutant_columns:
   top_stations[pollutant] = mean_pollutant_by_station[pollutant].sort_values(ascending=False).head(10)

# Step 3: Plotting
fig, axes = plt.subplots(len(pollutant_columns), 1, figsize=(10, 20))

for i, pollutant in enumerate(pollutant_columns):
    axes[i].barh(top_stations[pollutant].index, top_stations[pollutant].values, color='skyblue')
    axes[i].set_title(f'Top 10 stations by {pollutant}')
    axes[i].set_xlabel(f'{pollutant}')
    axes[i].invert_yaxis()  # Highest values on top

plt.tight_layout()
plt.show()

df.columns













